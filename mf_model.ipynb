{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5a077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import logging\n",
    "from surprise import Dataset, Reader, SVD, NMF, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/processed/reviews.csv\"\n",
    "output_path = \"models/mf_model.pkl\"\n",
    "algorithm = \"SVD\"\n",
    "custom_params = None\n",
    "teencode_path = \"resources/teencode.csv\"\n",
    "stopwords_path = \"resources/stopwords.txt\"\n",
    "phrases_path = \"resources/phrase_mapping.csv\"\n",
    "invalid_output_path = \"log/invalid_reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544f5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "log_dir = \"log\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_file = os.path.join(log_dir, \"train_mf_model.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(log_file, encoding=\"utf-8\"), logging.StreamHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    file_path: str,\n",
    "    sentiment_model=None,\n",
    "    text_processor=None,\n",
    "    filter_mismatch: bool = False,\n",
    "    invalid_output_path: str = 'reviews_invalid.csv',\n",
    "):\n",
    "    \"\"\"\n",
    "    Load rating data and optionally filter out mismatched sentiment-rating rows.\n",
    "    Keeps reviews without comments and only filters ones with comment mismatches.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to ratings CSV file.\n",
    "        sentiment_model: Pre-trained sentiment classification model.\n",
    "        text_processor: TextProcessor instance.\n",
    "        filter_mismatch (bool): Whether to remove mismatched sentiment-rating pairs.\n",
    "        invalid_output_path (str): File path to store removed rows if any.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: surprise.Dataset object\n",
    "    \"\"\"\n",
    "    from surprise import Dataset, Reader\n",
    "\n",
    "    logging.info(f\"Loading data from {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    total_before = len(df)\n",
    "\n",
    "    if filter_mismatch:\n",
    "        if sentiment_model is None or text_processor is None:\n",
    "            raise ValueError(\"Sentiment model and processor are required for filtering.\")\n",
    "\n",
    "        logging.info(\"Filtering mismatched sentiment and rating...\")\n",
    "\n",
    "        # Identify rows with comment to process\n",
    "        comment_mask = df[\"comment\"].notna() & df[\"comment\"].str.strip().ne(\"\")\n",
    "\n",
    "        df_comment = df[comment_mask].copy()\n",
    "        df_comment[\"processed\"] = df_comment[\"comment\"].astype(str).apply(text_processor.preprocess)\n",
    "        df_comment[\"predicted_sentiment\"] = sentiment_model.predict(df_comment[\"processed\"])\n",
    "\n",
    "        # Valid if rating matches predicted sentiment\n",
    "        df_comment[\"is_valid\"] = ~(\n",
    "            ((df_comment[\"rating\"] >= 4) & (df_comment[\"predicted_sentiment\"] == \"neg\")) |\n",
    "            ((df_comment[\"rating\"] <= 2) & (df_comment[\"predicted_sentiment\"] == \"pos\"))\n",
    "        )\n",
    "\n",
    "        # Combine: keep valid comments + all no-comment rows\n",
    "        mismatched = df_comment[~df_comment[\"is_valid\"]]\n",
    "        valid_comments = df_comment[df_comment[\"is_valid\"]]\n",
    "        df_nocomment = df[~comment_mask]\n",
    "        df_final = pd.concat([valid_comments, df_nocomment], ignore_index=True)\n",
    "\n",
    "        # Logging\n",
    "        logging.info(f\"Total reviews before filtering: {total_before}\")\n",
    "        logging.info(f\"Reviews with comment: {len(df_comment)}\")\n",
    "        logging.info(f\"Reviews removed due to mismatch: {len(mismatched)}\")\n",
    "        logging.info(f\"Remaining reviews after filtering: {len(df_final)}\")\n",
    "\n",
    "        # Save mismatched reviews\n",
    "        parent_dir = os.path.dirname(invalid_output_path)\n",
    "        if parent_dir:\n",
    "            os.makedirs(parent_dir, exist_ok=True)\n",
    "        mismatched.to_csv(invalid_output_path, index=False, encoding=\"utf-8\")\n",
    "        logging.info(f\"Mismatched reviews saved to {invalid_output_path}\")\n",
    "\n",
    "        df = df_final\n",
    "\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(df[[\"userId\", \"productId\", \"rating\"]], reader)\n",
    "    return data\n",
    "\n",
    "\n",
    "def train_model(data, algorithm=\"SVD\", params=None):\n",
    "    logging.info(f\"Training model using algorithm: {algorithm}\")\n",
    "    trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "\n",
    "    if algorithm == \"SVD\":\n",
    "        default_params = {\n",
    "            \"n_factors\": 20,\n",
    "            \"n_epochs\": 50,\n",
    "            \"lr_all\": 0.005,\n",
    "            \"reg_all\": 0.01,\n",
    "        }\n",
    "        model = SVD(**(params or default_params))\n",
    "    elif algorithm == \"NMF\":\n",
    "        default_params = {\"n_factors\": 50, \"n_epochs\": 50}\n",
    "        model = NMF(**(params or default_params))\n",
    "    elif algorithm == \"KNNBasic\":\n",
    "        default_params = {\n",
    "            \"k\": 40,\n",
    "            \"sim_options\": {\"name\": \"cosine\", \"user_based\": False},\n",
    "        }\n",
    "        model = KNNBasic(**(params or default_params))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported algorithm: {algorithm}\")\n",
    "\n",
    "    model.fit(trainset)\n",
    "\n",
    "    predictions = model.test(testset)\n",
    "\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "\n",
    "    logging.info(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "    return model, rmse, mae\n",
    "\n",
    "\n",
    "def save_model(model, output_path=\"model.pkl\"):\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    logging.info(f\"Model saved to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model_path=\"model.pkl\"):\n",
    "    try:\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "        logging.info(f\"Model loaded from {model_path}\")\n",
    "\n",
    "\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load model: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_sentiment_model(model_path):\n",
    "    \"\"\"Load a trained sentiment analysis model from file.\"\"\"\n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        logging.info(f\"Model loaded from {model_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load model: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "def get_user_recommendations(model, df, userId, top_k=10, exclude_purchased=True):\n",
    "    all_products = df[\"productId\"].unique()\n",
    "    user_products = set(df[df[\"userId\"] == userId][\"productId\"].values)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for productId in all_products:\n",
    "        if exclude_purchased and productId in user_products:\n",
    "            continue\n",
    "        pred = model.predict(userId, productId)\n",
    "        predictions.append((productId, pred.est))\n",
    "\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_recs = [prod_id for prod_id, _ in predictions[:top_k]]\n",
    "    return top_recs\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71b39cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 23:03:07,978 - INFO - Start training pipeline\n",
      "2025-06-21 23:03:07,980 - INFO - Loading data from data/processed/reviews.csv\n",
      "2025-06-21 23:03:08,664 - INFO - Training model using algorithm: SVD\n",
      "2025-06-21 23:03:14,830 - INFO - RMSE: 0.5547, MAE: 0.2968\n",
      "2025-06-21 23:03:15,194 - INFO - Model saved to models/mf_model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete\n",
      "RMSE: 0.5547209462162024\n",
      "MAE: 0.29682866027151567\n",
      "Model saved to: models/mf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Start training pipeline\")\n",
    "data = load_data(data_path)\n",
    "model, rmse, mae = train_model(data, algorithm, custom_params)\n",
    "save_model(model, output_path)\n",
    "\n",
    "print(\"✅ Training complete\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"Model saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de34b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.text_processor import TextProcessor\n",
    "\n",
    "# Initialize text processor\n",
    "processor = TextProcessor(\n",
    "    teencode_path=teencode_path,\n",
    "    stopword_path=stopwords_path,\n",
    "    phrase_mapping_path=phrases_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d29e652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 23:47:12,594 - INFO - Start training pipeline\n",
      "2025-06-21 23:47:12,723 - INFO - Model loaded from models/20250621_svm_model.pkl\n",
      "2025-06-21 23:47:12,725 - INFO - Loading data from data/processed/reviews.csv\n",
      "2025-06-21 23:47:13,249 - INFO - Filtering mismatched sentiment and rating...\n",
      "2025-06-21 23:50:03,380 - INFO - Total reviews before filtering: 99520\n",
      "2025-06-21 23:50:03,381 - INFO - Reviews removed due to mismatch: 17031\n",
      "2025-06-21 23:50:03,382 - INFO - Remaining reviews after filtering: 82489\n",
      "2025-06-21 23:50:03,621 - INFO - Mismatched reviews saved to log/invalid_reviews.csv\n",
      "2025-06-21 23:50:03,776 - INFO - Training model using algorithm: SVD\n",
      "2025-06-21 23:50:05,445 - INFO - RMSE: 0.8708, MAE: 0.5462\n",
      "2025-06-21 23:50:05,554 - INFO - Model saved to models/mf_model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete\n",
      "RMSE: 0.870793846548323\n",
      "MAE: 0.546169456816573\n",
      "Model saved to: models/mf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Start training pipeline\")\n",
    "# Load model and preprocess input\n",
    "sentiment_model = load_sentiment_model(\"models/20250621_svm_model.pkl\")\n",
    "data = load_data(data_path, sentiment_model, processor, filter_mismatch=True, invalid_output_path=invalid_output_path)\n",
    "model, rmse, mae = train_model(data, algorithm, custom_params)\n",
    "save_model(model, output_path)\n",
    "\n",
    "print(\"✅ Training complete\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"Model saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bef09cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 23:03:16,184 - INFO - Model loaded from models/mf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "mf_model = load_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d86332bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[138934620,\n",
       " 140120577,\n",
       " 1667493,\n",
       " 194130726,\n",
       " 216090625,\n",
       " 251928260,\n",
       " 263980370,\n",
       " 276107155,\n",
       " 276256755,\n",
       " 277024165]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_recommendations(mf_model, df, 21665899)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
